{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from DecisionTree import *\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Decision Tree Project </h1>\n",
    "In this project we are trying to train a model based on Decision Trees for predicting satistaction in public flights.\n",
    "\n",
    "we split the project in three main parts: \n",
    "\n",
    "1- Data Cleaning and Oraganization\n",
    "\n",
    "2- Building the Tree\n",
    "\n",
    "3- Evaluation and Benchmarking\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Handeling </h3>\n",
    "\n",
    "There are several operations needed to be preformed on data to make it ready for training.\n",
    "\n",
    "First we should categorize continuous variables and limit their domains. there are many ways to do this but in this project we split continuous varibles such that each category contains a fixed precentage of the total data. this way there is a lower bound on the given data for every decision we make in the tree. this precentage is a hyper parameter of the tree and can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(series: pd.Series, precentInGroup):\n",
    "    # categorzies a single column of dataframe with a given percentage\n",
    "    CountInGroup = int(len(series) * precentInGroup)\n",
    "    count = int(1 / precentInGroup)\n",
    "    series = series.sort_values()\n",
    "    bins = [-math.inf]\n",
    "    border = 0\n",
    "    for i in range(int(count)):\n",
    "        bins.append(series.iloc[border])\n",
    "        border += CountInGroup\n",
    "    bins.append(math.inf)\n",
    "    series = pd.cut(series, bins, duplicates=\"drop\")\n",
    "    out = series.astype(str).sort_index()\n",
    "    return (out, bins)\n",
    "\n",
    "def Categorization1(TrainData, TestData, features, categorizedFeatures):\n",
    "    # this function is the categorization procedure. calculate the category bounds for\n",
    "    # every continuous feature in train data. then it applies those bounds for test data.\n",
    "    # returns feature domains for every feature in data. \n",
    "    featuresDomains = {}\n",
    "    for feature in features:\n",
    "        if feature == \"id\" or feature == \"Unnamed: 0\":\n",
    "            continue\n",
    "        if feature in categorizedFeatures:\n",
    "            TrainData[feature], bins = categorize(TrainData[feature], 0.3)\n",
    "            TestData[feature] = series = pd.cut(TestData[feature], bins, duplicates=\"drop\").astype(str)\n",
    "        series = TrainData[feature]\n",
    "        domain = set()\n",
    "        for item in series:\n",
    "            if item not in domain:\n",
    "                domain.add(item)\n",
    "        featuresDomains[feature] = domain\n",
    "    return featuresDomains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After categorizing we should encode variable domains to integers. this is because string comparison is much slower than integer comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncodeData(data: pd.DataFrame, featureDomains):\n",
    "    # Encodes every feature domain in data to range(0...n) \n",
    "    for feature in featureDomains:\n",
    "        domain = featureDomains[feature]\n",
    "        featureDomains[feature] = list(range(len(domain)))\n",
    "        ReplaceList = {}\n",
    "        for encoding, item in enumerate(domain):\n",
    "            ReplaceList[item] = encoding\n",
    "        data[feature] = data[feature].replace(ReplaceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we combine these functions to clean our train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanDataV1(TrainData, TestData, features, categorizedFeatures):\n",
    "    featureDomains = Categorization1(TrainData, TestData, features, categorizedFeatures)\n",
    "    EncodeData(TestData, copy.deepcopy(featureDomains))\n",
    "    EncodeData(TrainData, featureDomains)\n",
    "    return featureDomains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Making The Tree</h3>\n",
    "our tree structure consist of two main components:\n",
    "\n",
    "1- Decision Nodes\n",
    "\n",
    "2- Leaf Nodes\n",
    "\n",
    "in Decision Nodes we make a decision for a fixed feature and decend the three to lower depths.\n",
    "\n",
    "in Leaf Nodes we classify a entry based on the probability distribution that lives in the node.\n",
    "\n",
    "because there is the chance of overfitting in decision trees we would like to somehow prune the made tree. in this project we preprune the tree by limiting the depth of tree. this makes depth our second hyperparameter. we build the tree by recursively finding the most important feature \n",
    "spliting the database based on its value. when our depth exceeds a certain threshold or the gini index / entropy of the feature equals zero we should make a leafnode based on the distribution of labels in the parent node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree making procedure (do not run this)\n",
    "self.feature = self.pickBestFeature(importance)\n",
    "self.used.add(self.feature)\n",
    "self.makeChilds()\n",
    "self.used.remove(self.feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to pick the best feature we iterate though each not fixed feature and pick the one with the most gain in importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickBestFeature(self, importance):\n",
    "        bestFeature = None\n",
    "        MaximumGain = -math.inf \n",
    "        for feature in self.domains:\n",
    "            if feature not in self.used:\n",
    "                gain = self.calculateGain(feature, importance)\n",
    "                if MaximumGain < gain:\n",
    "                    MaximumGain = gain\n",
    "                    bestFeature = feature\n",
    "        return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate gain for each feature, first we average the importance of a nodes children\n",
    "then we calculate the diffrence between this weighted average and the nodes importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateGain(self, feature, importance):\n",
    "        totalChildImportance = 0\n",
    "        domain = self.domains[feature]\n",
    "        for item in domain:\n",
    "            nextData = query(self.data, feature, item)\n",
    "            if len(nextData) > 0:\n",
    "                totalChildImportance += len(nextData) * importance(self.labels, nextData)\n",
    "        averageChildImportance = totalChildImportance / len(domain)\n",
    "        parentImportance = importance(self.labels, self.data)\n",
    "        return parentImportance - averageChildImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use gini index or information gain to calculate importance. this is due to the fact that \n",
    "a node with lower importance means that the data is more uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateGini(labels, data: pd.DataFrame):\n",
    "        Gini = 0\n",
    "        for label in labels:\n",
    "            prob = len(query(data, \"satisfaction\", label)) / len(data)\n",
    "            if prob == 0:\n",
    "                continue\n",
    "            Gini += prob * (1 - prob)\n",
    "        return Gini\n",
    "\n",
    "def calculateEntropy(labels, data: pd.DataFrame):\n",
    "        entorpy = 0\n",
    "        for label in labels:\n",
    "            prob = len(query(data, \"satisfaction\", label)) / len(data)\n",
    "            if prob == 0:\n",
    "                continue\n",
    "            entorpy += prob * math.log2(prob)\n",
    "        return -entorpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after finding the best feature, we split the from it. and recurviely make the tree until the depth threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeChilds(self):\n",
    "        for item in self.domains[self.feature]:\n",
    "            nextData = query(self.data, self.feature, item)\n",
    "            if len(nextData) != 0:\n",
    "                entropy = self.importance(self.labels, nextData)\n",
    "            if len(nextData) == 0:\n",
    "                self.Childs[item] = LeafNode(self.labels, self.data)\n",
    "            elif entropy == 0 or self.depth == 0:\n",
    "                self.Childs[item] = LeafNode(self.labels, nextData)\n",
    "            else:\n",
    "                self.Childs[item] = DecisionNode(nextData, self.domains, self.labels, self.depth - 1, self.used, self.importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation & Benchmarking </h3>\n",
    "\n",
    "after successfuly building the tree, its time for measuring its performance. first we write a function for classifying a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(self, entry):\n",
    "        value = entry[self.feature]\n",
    "        return self.Childs[value].classify(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we make two procedures for training and testing with diffrenct hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(TrainData, featuresDomains, depth, importance):\n",
    "    return DesicionTree(featuresDomains, TrainData, featuresDomains[\"satisfaction\"], depth, set([\"satisfaction\"]), importance)\n",
    "\n",
    "def Test(TestData, tree):\n",
    "    #returns the accuracy of the model\n",
    "    correct = 0\n",
    "    for i in range(len(TestData)):\n",
    "        entry = TestData.iloc[i]\n",
    "        correct += tree.classify(entry) == TestData.iloc[i][\"satisfaction\"]\n",
    "    return (correct / len(TestData)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can finally import our data and clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\user\\anaconda3\\envs\\cs188\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "DataPath = \"Data/Airplane.csv\"\n",
    "DataFrame = pd.read_csv(DataPath)\n",
    "TestData = DataFrame.iloc[:2000]\n",
    "TrainData = DataFrame.iloc[2000:]\n",
    "features = TestData.keys()\n",
    "categorizedFeatures = set([\"Age\",\n",
    "                           \"Flight Distance\",\n",
    "                           \"Departure Delay in Minutes\",\n",
    "                           \"Arrival Delay in Minutes\"])\n",
    "featuresDomains = CleanDataV1(TrainData, TestData, features, categorizedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can finally measure our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 10.0\n",
      "Train Accuracy: 91.16913958235202\n"
     ]
    }
   ],
   "source": [
    "depth = 7\n",
    "tree = Train(TrainData, featuresDomains, depth, DecisionNode.calculateEntropy)\n",
    "testAccuracy = Test(TestData, tree)\n",
    "trainAccuracy = Test(TrainData, tree)\n",
    "print(f\"Test Accuracy: {testAccuracy}\\nTrain Accuracy: {trainAccuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs188",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
